2023-04-23 23:46:41,781 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-poznan,oferta,1002539100 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-23 23:53:46,826 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-lubuskie,oferta,9884317 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 00:00:13,788 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-podkarpackie,oferta,9884321 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 00:05:12,319 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-ds-analiz-danych-e-commerce-lublin-melgiewska-27,oferta,1002512099 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3784 (char 3783)
2023-04-24 00:19:14,538 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/database-developer-krakow-puszkarska-7j,oferta,1002504524 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2243 (char 2242)
2023-04-24 00:19:22,923 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-podlaskie,oferta,9884322 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 00:22:55,066 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-warminsko-mazurskie,oferta,9884326 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 00:38:34,287 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/programista-c++-wieliczka-czarnochowska-8,oferta,1002542438 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3093 (char 3092)
2023-04-24 00:41:20,457 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-ds-analiz-i-raportowania-warszawa-aleje-jerozolimskie-142b,oferta,1002501828 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2010 (char 2009)
2023-04-24 00:44:46,546 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-swietokrzyskie,oferta,9884325 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 01:22:46,968 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/analityk-biznesowy-procesow-oceny-ryzyka-kredytowego-warszawa,oferta,1002494290 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 1631 (char 1630)
2023-04-24 01:50:50,140 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/administrator-systemow-bankowych-i-monitoringu-warszawa-grzybowska-81,oferta,1002504438 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 1633 (char 1632)
2023-04-24 01:54:27,950 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-slaskie,oferta,9884324 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 02:04:46,265 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-opolskie,oferta,9884320 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 02:24:55,708 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-kujawsko-pomorskie,oferta,9884314 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 02:26:12,719 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-pomorskie,oferta,9884323 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 02:27:56,321 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/mlodszy-programista-net-systemy-logistyczne-w-dziale-realizacji-projektow-gliwice-leona-wyczolkowskiego-125,oferta,1002544829 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2551 (char 2550)
2023-04-24 02:34:22,076 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/starszy-programista-java-warszawa,oferta,1002540535 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2755 (char 2754)
2023-04-24 02:48:51,429 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/staz-w-obszarze-programowanie-it-radom,oferta,1002537945 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3386 (char 3385)
2023-04-24 03:06:49,646 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/programista-ds-backend-java-warszawa-targowa-25,oferta,1002491920 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2973 (char 2972)
2023-04-24 03:19:12,021 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-mazowieckie,oferta,9884319 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 03:19:57,124 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/application-support-specialist-wealth-personal-banking-it-krakow-kapelanka-42a,oferta,1002520322 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4637 (char 4636)
2023-04-24 03:20:32,314 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen - httplib_response = self._make_request( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request - self._validate_conn(conn) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn - conn.connect() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connection.py", line 414, in connect - self.sock = ssl_wrap_socket( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket - ssl_sock = _ssl_wrap_socket_impl( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl - return ssl_context.wrap_socket(sock, server_hostname=server_hostname) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 517, in wrap_socket - return self.sslsocket_class._create( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1075, in _create - self.do_handshake() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1346, in do_handshake - self._sslobj.do_handshake() - ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 489, in send - resp = conn.urlopen( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen - retries = retries.increment( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\retry.py", line 592, in increment - raise MaxRetryError(_pool, url, error or ResponseError(cause)) - urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Max retries exceeded with url: /praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992)'))) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 223, in listing_pipeline_main - substring = scrape_listing_from_json(url) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 25, in scrape_listing_from_json - response = requests.get(url, timeout=timeout) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 73, in get - return request("get", url, params=params, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 59, in request - return session.request(method=method, url=url, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 587, in request - resp = self.send(prep, **send_kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 701, in send - r = adapter.send(request, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 563, in send - raise SSLError(e, request=request) - requests.exceptions.SSLError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Max retries exceeded with url: /praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992)')))
2023-04-24 03:31:01,302 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/client-implementation-engineer-warszawa-zajecza-15,oferta,1002513474 - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request - six.raise_from(e, None) - File "<string>", line 3, in raise_from - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request - httplib_response = conn.getresponse() -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1374, in getresponse - response.begin() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 318, in begin - version, status, reason = self._read_status() -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 279, in _read_status - line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1") -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto - return self._sock.recv_into(b) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1278, in recv_into - return self.read(nbytes, buffer) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1134, in read - return self._sslobj.read(len, buffer) -  - TimeoutError: The read operation timed out -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 489, in send - resp = conn.urlopen( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen - retries = retries.increment( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\retry.py", line 550, in increment - raise six.reraise(type(error), error, _stacktrace) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\packages\six.py", line 770, in reraise - raise value - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen - httplib_response = self._make_request( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 451, in _make_request - self._raise_timeout(err=e, url=url, timeout_value=read_timeout) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 340, in _raise_timeout - raise ReadTimeoutError( - urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Read timed out. (read timeout=5) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 223, in listing_pipeline_main - substring = scrape_listing_from_json(url) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 25, in scrape_listing_from_json - response = requests.get(url, timeout=timeout) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 73, in get - return request("get", url, params=params, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 59, in request - return session.request(method=method, url=url, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 587, in request - resp = self.send(prep, **send_kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 701, in send - r = adapter.send(request, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 578, in send - raise ReadTimeout(e, request=request) - requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Read timed out. (read timeout=5)
2023-04-24 03:33:17,250 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/starszy-specjalista-ds-rozwoju-narzedzi-oceny-ryzyka-kredytowego-warszawa,oferta,1002504274 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3005 (char 3004)
2023-04-24 03:35:09,555 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-malopolskie,oferta,9884318 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 03:39:34,137 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/embedded-software-engineer-warszawa-ogrodowa-58,oferta,1002530757 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2419 (char 2418)
2023-04-24 03:40:40,544 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/site-reliability-engineer-devops-gdynia-aleja-zwyciestwa-96-98,oferta,1002501098 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3376 (char 3375)
2023-04-24 04:04:49,424 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-lubelskie,oferta,9884316 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 04:29:01,645 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-zachodniopomorskie,oferta,9884327 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 04:44:59,926 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/architekt-systemowy-warszawa-targowa-25,oferta,1002549502 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4759 (char 4758)
2023-04-24 04:52:21,209 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/full-stack-developer-szczecin,oferta,1002491480 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2147 (char 2146)
2023-04-24 05:00:08,969 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/podinspektor-w-referacie-informatyki-szczecin-blogoslawionego-wincentego-kadlubka-12,oferta,1002537613 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 7646 (char 7645)
2023-04-24 05:19:12,884 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-lodzkie,oferta,9884315 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-04-24 05:51:52,767 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/staz-w-obszarze-programowanie-it-warszawa-rondo-daszynskiego-1,oferta,1002537944 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3386 (char 3385)
2023-04-24 05:57:14,730 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/embedded-team-leader-gdynia-aleja-zwyciestwa-96-98,oferta,1002491055 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2455 (char 2454)
2023-04-24 06:23:39,966 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-dolnoslaskie,oferta,9884313 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)
2023-05-01 15:54:51,634 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/sap-basis-administrator-bielsko-biala-mickiewicza-3,oferta,1002563187 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 7759 (char 7758)
2023-05-01 16:17:50,938 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/senior-java-developer-wroclaw,oferta,1002554922 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4175 (char 4174)
2023-05-01 16:19:30,627 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/podinspektor-w-referacie-informatyki-szczecin-blogoslawionego-wincentego-kadlubka-12,oferta,1002537613 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 7453 (char 7452)
2023-05-01 16:21:32,576 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/programista-c++-wieliczka-czarnochowska-8,oferta,1002542438 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2900 (char 2899)
2023-05-01 16:22:17,488 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-kujawsko-pomorskie,oferta,9884314 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 16:34:55,349 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-malopolskie,oferta,9884318 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 16:35:56,238 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/embedded-software-engineer-warszawa-ogrodowa-58,oferta,1002530757 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2226 (char 2225)
2023-05-01 16:36:09,348 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-lubuskie,oferta,9884317 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 16:39:14,485 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/senior-java-developer-gdansk,oferta,1002554920 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4175 (char 4174)
2023-05-01 16:44:35,279 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-pomorskie,oferta,9884323 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 16:47:49,613 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-mazowieckie,oferta,9884319 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 16:53:17,540 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/database-developer-krakow-puszkarska-7j,oferta,1002504524 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2050 (char 2049)
2023-05-01 16:55:40,954 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/starszy-programista-java-warszawa,oferta,1002540535 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2562 (char 2561)
2023-05-01 16:58:28,618 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-warminsko-mazurskie,oferta,9884326 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 17:01:06,040 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/administrator-systemow-bankowych-i-monitoringu-warszawa-grzybowska-81,oferta,1002504438 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 1440 (char 1439)
2023-05-01 17:11:17,494 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalistka-specjalista-ds-informatyki-lomna-las-pow-nowodworski-dobra-3,oferta,1002563637 - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request - self._validate_conn(conn) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn - conn.connect() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connection.py", line 414, in connect - self.sock = ssl_wrap_socket( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket - ssl_sock = _ssl_wrap_socket_impl( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl - return ssl_context.wrap_socket(sock, server_hostname=server_hostname) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 517, in wrap_socket - return self.sslsocket_class._create( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1075, in _create - self.do_handshake() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1346, in do_handshake - self._sslobj.do_handshake() - TimeoutError: _ssl.c:975: The handshake operation timed out -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 489, in send - resp = conn.urlopen( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen - retries = retries.increment( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\retry.py", line 550, in increment - raise six.reraise(type(error), error, _stacktrace) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\packages\six.py", line 770, in reraise - raise value - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen - httplib_response = self._make_request( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 389, in _make_request - self._raise_timeout(err=e, url=url, timeout_value=conn.timeout) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 340, in _raise_timeout - raise ReadTimeoutError( - urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Read timed out. (read timeout=5) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 223, in listing_pipeline_main - substring = scrape_listing_from_json(url) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 25, in scrape_listing_from_json - response = requests.get(url, timeout=timeout) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 73, in get - return request("get", url, params=params, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 59, in request - return session.request(method=method, url=url, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 587, in request - resp = self.send(prep, **send_kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 701, in send - r = adapter.send(request, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 578, in send - raise ReadTimeout(e, request=request) - requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Read timed out. (read timeout=5)
2023-05-01 17:14:51,135 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/architekt-systemowy-warszawa-targowa-25,oferta,1002549502 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4566 (char 4565)
2023-05-01 17:24:54,179 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-lubelskie,oferta,9884316 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 17:48:13,249 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-zachodniopomorskie,oferta,9884327 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 18:03:10,561 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-poznan,oferta,1002539100 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 18:23:40,115 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/zastepca-dyrektora-do-spraw-zespolu-zamiejscowego-w-wydziale-informatyki-krakow,oferta,1002554316 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 7021 (char 7020)
2023-05-01 18:27:47,391 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/software-developer-labview-wroclaw-kwiatkowskiego-4,oferta,1002536537 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3730 (char 3729)
2023-05-01 18:32:31,461 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-swietokrzyskie,oferta,9884325 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 18:36:47,986 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/staz-w-obszarze-programowanie-it-radom,oferta,1002537945 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3253 (char 3252)
2023-05-01 18:37:28,591 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-podkarpackie,oferta,9884321 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 19:05:15,702 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-specjalistka-rs-power-bi-warszawa-rotmistrza-witolda-pileckiego-65,oferta,1002550558 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2143 (char 2142)
2023-05-01 19:17:06,181 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/projektant-architekt-systemow-it-warszawa-rotmistrza-witolda-pileckiego-65,oferta,1002555344 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4103 (char 4102)
2023-05-01 19:27:13,245 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-slaskie,oferta,9884324 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 19:32:38,478 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/application-support-specialist-wealth-personal-banking-it-krakow-kapelanka-42a,oferta,1002520322 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4444 (char 4443)
2023-05-01 19:33:12,947 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/junior-iam-engineer-warszawa-aleje-jerozolimskie-98,oferta,1002556601 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3290 (char 3289)
2023-05-01 19:39:55,509 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/net-c%23-developer-bytom,oferta,1002565036 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2123 (char 2122)
2023-05-01 19:42:35,223 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/programista-c%23-poznan-golezycka-25a,oferta,1002550855 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 1842 (char 1841)
2023-05-01 20:03:40,724 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-podlaskie,oferta,9884322 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 20:08:11,698 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-dolnoslaskie,oferta,9884313 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 20:18:23,627 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/staz-w-obszarze-programowanie-it-warszawa-rondo-daszynskiego-1,oferta,1002537944 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3253 (char 3252)
2023-05-01 20:30:29,465 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-opolskie,oferta,9884320 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-01 20:39:27,736 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/starszy-specjalista-ds-rozwoju-narzedzi-oceny-ryzyka-kredytowego-warszawa,oferta,1002504274 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2812 (char 2811)
2023-05-01 20:42:33,416 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/mlodszy-programista-net-systemy-logistyczne-w-dziale-realizacji-projektow-gliwice-leona-wyczolkowskiego-125,oferta,1002544829 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2358 (char 2357)
2023-05-01 20:59:55,506 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/sap-basis-administrator-wroclaw-rynek-36-37,oferta,1002563186 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 7759 (char 7758)
2023-05-01 21:09:30,783 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/senior-java-developer-poznan,oferta,1002554921 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4175 (char 4174)
2023-05-01 21:21:28,274 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-lodzkie,oferta,9884315 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-07 16:44:43,010 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-specjalistka-rs-power-bi-warszawa-rotmistrza-witolda-pileckiego-65,oferta,1002550558 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2143 (char 2142)
2023-05-07 17:31:34,577 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/junior-iam-engineer-warszawa-aleje-jerozolimskie-98,oferta,1002556601 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3290 (char 3289)
2023-05-07 17:55:33,543 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/programista-c%23-poznan-golezycka-25a,oferta,1002550855 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 1842 (char 1841)
2023-05-07 18:31:04,191 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/mlodszy-programista-net-systemy-logistyczne-w-dziale-realizacji-projektow-gliwice-leona-wyczolkowskiego-125,oferta,1002544829 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2358 (char 2357)
2023-05-07 19:09:17,943 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/senior-java-developer-poznan,oferta,1002554921 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4175 (char 4174)
2023-05-07 19:13:25,406 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/embedded-software-engineer-warszawa-ogrodowa-58,oferta,1002530757 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2226 (char 2225)
2023-05-07 20:01:14,079 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/programista-c++-wieliczka-czarnochowska-8,oferta,1002542438 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2900 (char 2899)
2023-05-07 20:03:36,775 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/senior-java-developer-wroclaw,oferta,1002554922 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4175 (char 4174)
2023-05-07 20:04:53,202 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/architekt-systemowy-warszawa-targowa-25,oferta,1002549502 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4566 (char 4565)
2023-05-07 20:05:01,222 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/sap-basis-administrator-bielsko-biala-mickiewicza-3,oferta,1002563187 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 7759 (char 7758)
2023-05-07 20:25:28,334 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/net-c%23-developer-bytom,oferta,1002565036 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2123 (char 2122)
2023-05-07 20:29:22,284 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/sap-basis-administrator-wroclaw-rynek-36-37,oferta,1002563186 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 7759 (char 7758)
2023-05-07 20:34:27,142 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-ka-informatyk-w-sekcji-systemu-teta-edu-wroclaw-wybrzeze-stanislawa-wyspianskiego-27,oferta,1002567275 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2800 (char 2799)
2023-05-07 20:38:31,924 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/application-support-specialist-wealth-personal-banking-it-krakow-kapelanka-42a,oferta,1002520322 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4444 (char 4443)
2023-05-07 21:00:23,305 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/projektant-architekt-systemow-it-warszawa-rotmistrza-witolda-pileckiego-65,oferta,1002555344 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4103 (char 4102)
2023-05-07 21:32:59,849 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/software-developer-labview-wroclaw-kwiatkowskiego-4,oferta,1002536537 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3730 (char 3729)
2023-05-07 21:43:35,065 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/senior-java-developer-gdansk,oferta,1002554920 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4175 (char 4174)
2023-05-07 22:06:14,016 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/starszy-specjalista-ds-rozwoju-narzedzi-oceny-ryzyka-kredytowego-warszawa,oferta,1002569151 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2812 (char 2811)
2023-05-18 13:02:40,379 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:02:48,363 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:02:49,438 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:02:50,513 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:02:51,585 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:02:52,641 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 12). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:02:53,714 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:02:54,774 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:03:31,263 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:03:38,424 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:04:18,258 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:04:24,387 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (187, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:04:25,467 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (187, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:05:07,547 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:05:14,928 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:05:16,019 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:05:17,084 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 12). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:05:18,163 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:05:19,234 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 12). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:06:07,213 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:06:13,976 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:06:15,103 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (187, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:06:16,191 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 12). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:06:17,260 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:06:18,324 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:06:56,797 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:07:03,413 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:07:04,489 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:07:05,566 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:07:06,641 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:07:07,713 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:07:52,393 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:08:00,132 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:08:01,216 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:08:02,302 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 12). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:08:03,394 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:08:04,469 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:08:05,545 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:08:06,661 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (187, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:08:07,763 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 12). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:08:52,348 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:08:59,140 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:09:00,217 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:09:01,289 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:09:39,772 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:09:46,851 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:09:47,948 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:09:49,008 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:09:50,086 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:09:51,151 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:10:33,068 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:10:39,389 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:10:40,460 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:10:41,523 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:11:20,073 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:11:27,010 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:11:28,095 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:11:29,185 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:11:30,252 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 12). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:11:31,313 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:12:06,420 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:12:13,874 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:12:15,000 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (187, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:12:16,062 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 73, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:17:59,767 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 46, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:18:06,062 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 74, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:18:07,124 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 74, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 12). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:18:08,184 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 74, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (191, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:18:45,720 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 46, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:18:52,539 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 74, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (189, 11). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:18:53,668 - main.scrape_one_page - ERROR - log_exception - No viewBox objects found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 74, in scrape_one_page - loc_button.click() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 93, in click - self._execute(Command.CLICK_ELEMENT) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 403, in _execute - return self._parent.execute(command, params) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 440, in execute - self.error_handler.check_response(response) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 245, in check_response - raise exception_class(message, screen, stacktrace) - selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <div data-test="offer-locations-button" class="JobOfferstyles__LocationsCountWrapper-sc-1rq6ue2-17 grvHWr">...</div> is not clickable at point (187, 12). Other element would receive the click: <div class="cookies_cvyuaxh">...</div> - (Session info: headless chrome=113.0.5672.94) - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C15A7A] - 	(No symbol) [0x00C14336] - 	(No symbol) [0x00C1267B] - 	(No symbol) [0x00C11797] - 	(No symbol) [0x00C094A5] - 	(No symbol) [0x00C2B8FC] - 	(No symbol) [0x00C08EC6] - 	(No symbol) [0x00C2BC54] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 
2023-05-18 13:19:26,405 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 46, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 92, in until - time.sleep(self._poll) - KeyboardInterrupt
2023-05-18 16:10:25,429 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-lubelskie,oferta,9884316 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 16:42:31,107 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-lubuskie,oferta,9884317 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 16:46:11,574 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/application-support-specialist-wealth-personal-banking-it-krakow-kapelanka-42a,oferta,1002578438 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4444 (char 4443)
2023-05-18 16:47:38,956 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/tester-wydajnosciowy-warszawa,oferta,1002578741 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3481 (char 3480)
2023-05-18 16:55:21,189 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-rzeszow,oferta,1002588063 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 17:03:50,371 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-lodzkie,oferta,9884315 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 17:08:15,700 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-mazowieckie,oferta,9884319 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 17:13:16,735 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-poznan,oferta,1002539100 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 17:13:42,085 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-bialystok,oferta,1002588051 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 17:18:06,128 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-gdansk,oferta,1002588053 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 17:18:14,137 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-dolnoslaskie,oferta,9884313 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 17:19:53,009 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-bydgoszcz,oferta,1002588052 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 17:27:44,326 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/architekt-rozwiazan-solution-architect-warszawa,oferta,1002594677 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3259 (char 3258)
2023-05-18 17:30:15,591 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-torun,oferta,1002588065 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 17:35:33,568 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-warszawa,oferta,1002588066 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 17:48:28,144 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/starszy-programista-java-warszawa,oferta,1002540535 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2562 (char 2561)
2023-05-18 17:53:17,170 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/project-manager-warszawa,oferta,1002586520 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 5094 (char 5093)
2023-05-18 17:54:06,230 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-zachodniopomorskie,oferta,9884327 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 18:01:41,297 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-opolskie,oferta,9884320 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 18:05:05,680 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/analityk-ds-rozwoju-procesow-oceny-ryzyka-kredytowego-warszawa,oferta,1002577227 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 1438 (char 1437)
2023-05-18 18:06:40,547 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-kielce,oferta,1002588056 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 18:16:21,923 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-szczecin,oferta,1002588064 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 18:26:54,258 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-kujawsko-pomorskie,oferta,9884314 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 18:29:22,850 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-zielona-gora,oferta,1002588068 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 18:33:12,774 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-lublin,oferta,1002588058 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 18:37:29,349 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-lodz,oferta,1002588059 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 18:46:44,947 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-olsztyn,oferta,1002588060 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 18:56:49,479 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-malopolskie,oferta,9884318 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 19:03:43,460 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/mes-system-developer-consultant-krakow,oferta,1002594898 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3094 (char 3093)
2023-05-18 19:04:36,274 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/web-analyst-warszawa-geodezyjna-76,oferta,1002579402 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2021 (char 2020)
2023-05-18 19:08:06,196 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-katowice,oferta,1002588055 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 19:12:22,635 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-slaskie,oferta,9884324 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 19:15:10,806 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-wroclaw,oferta,1002588067 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 19:15:18,138 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-poznan,oferta,1002588062 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 19:15:32,926 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/project-manager-pmo-contributor-warszawa-pulawska-435,oferta,1002580318 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 1193 (char 1192)
2023-05-18 19:19:25,168 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-swietokrzyskie,oferta,9884325 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 19:22:51,157 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-pomorskie,oferta,9884323 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 19:24:59,956 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/game-developer-katowice-pod-mlynem-1c,oferta,1002602121 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 1220 (char 1219)
2023-05-18 19:33:23,199 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-krakow,oferta,1002588057 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 19:33:49,011 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/programista-net-kostrzyn-nad-odra-aleja-milenijna-14,oferta,1002588734 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2005 (char 2004)
2023-05-18 19:34:57,851 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-podkarpackie,oferta,9884321 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 19:36:45,093 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-podlaskie,oferta,9884322 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 355, in raw_decode - raise JSONDecodeError("Expecting value", s, err.value) from None - json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2023-05-18 19:38:17,777 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-gorzow-wielkopolski,oferta,1002588054 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 19:39:32,064 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-warminsko-mazurskie,oferta,9884326 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)
2023-05-18 19:40:57,941 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/specjalista-rozwiazan-wms-opole,oferta,1002588061 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 321, in main - listing_pipeline_main(url, _tech_set, succesfull_file) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 303, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4358 (char 4357)
2023-05-18 19:43:08,448 - main.main - ERROR - log_exception - saving listing JSON to database - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\main.py", line 56, in <module> - mongodb.save_dict_from_file_to_collection(collection_succesfull, SUCCESFULL_EXTRACTIONS) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\db_functions_mongodb.py", line 53, in save_dict_from_file_to_collection - date_str = doc['publication_month'] -  - KeyError: 'publication_month'
