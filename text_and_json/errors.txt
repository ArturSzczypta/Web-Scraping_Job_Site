2023-04-24 00:44:46,546 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-swietokrzyskie,oferta,9884325 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)

2023-04-24 01:22:46,968 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/analityk-biznesowy-procesow-oceny-ryzyka-kredytowego-warszawa,oferta,1002494290 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 1631 (char 1630)

2023-04-24 00:19:14,538 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/database-developer-krakow-puszkarska-7j,oferta,1002504524 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2243 (char 2242)

2023-04-24 04:44:59,926 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/architekt-systemowy-warszawa-targowa-25,oferta,1002549502 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 4759 (char 4758)

2023-04-24 04:52:21,209 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/full-stack-developer-szczecin,oferta,1002491480 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 2147 (char 2146)

2023-05-01 16:47:49,613 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-mazowieckie,oferta,9884319 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3357 (char 3356)

2023-05-18 13:02:40,379 - main.scrape_one_page - ERROR - log_exception - Terms of Service button not found - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_urls.py", line 45, in scrape_one_page - accept_button = WebDriverWait(browser, 10).until( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until - raise TimeoutException(message, screen, stacktrace) - selenium.common.exceptions.TimeoutException: Message: - Stacktrace: - Backtrace: - 	GetHandleVerifier [0x00D4DCE3+50899] - 	(No symbol) [0x00CDE111] - 	(No symbol) [0x00BE5588] - 	(No symbol) [0x00C108F9] - 	(No symbol) [0x00C10AFB] - 	(No symbol) [0x00C3F902] - 	(No symbol) [0x00C2B944] - 	(No symbol) [0x00C3E01C] - 	(No symbol) [0x00C2B6F6] - 	(No symbol) [0x00C07708] - 	(No symbol) [0x00C0886D] - 	GetHandleVerifier [0x00FB3EAE+2566302] - 	GetHandleVerifier [0x00FE92B1+2784417] - 	GetHandleVerifier [0x00FE327C+2759788] - 	GetHandleVerifier [0x00DE5740+672048] - 	(No symbol) [0x00CE8872] - 	(No symbol) [0x00CE41C8] - 	(No symbol) [0x00CE42AB] - 	(No symbol) [0x00CD71B7] - 	BaseThreadInitThunk [0x765700F9+25] - 	RtlGetAppContainerNamedObjectPath [0x77167BBE+286] - 	RtlGetAppContainerNamedObjectPath [0x77167B8E+238] - 



2023-04-24 03:20:32,314 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen - httplib_response = self._make_request( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request - self._validate_conn(conn) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn - conn.connect() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connection.py", line 414, in connect - self.sock = ssl_wrap_socket( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket - ssl_sock = _ssl_wrap_socket_impl( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl - return ssl_context.wrap_socket(sock, server_hostname=server_hostname) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 517, in wrap_socket - return self.sslsocket_class._create( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1075, in _create - self.do_handshake() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1346, in do_handshake - self._sslobj.do_handshake() - ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 489, in send - resp = conn.urlopen( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen - retries = retries.increment( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\retry.py", line 592, in increment - raise MaxRetryError(_pool, url, error or ResponseError(cause)) - urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Max retries exceeded with url: /praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992)'))) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 223, in listing_pipeline_main - substring = scrape_listing_from_json(url) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 25, in scrape_listing_from_json - response = requests.get(url, timeout=timeout) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 73, in get - return request("get", url, params=params, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 59, in request - return session.request(method=method, url=url, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 587, in request - resp = self.send(prep, **send_kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 701, in send - r = adapter.send(request, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 563, in send - raise SSLError(e, request=request) - requests.exceptions.SSLError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Max retries exceeded with url: /praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992)')))


2023-04-24 03:20:32,314 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen - httplib_response = self._make_request( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request - self._validate_conn(conn) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn - conn.connect() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connection.py", line 414, in connect - self.sock = ssl_wrap_socket( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket - ssl_sock = _ssl_wrap_socket_impl( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl - return ssl_context.wrap_socket(sock, server_hostname=server_hostname) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 517, in wrap_socket - return self.sslsocket_class._create( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1075, in _create - self.do_handshake() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1346, in do_handshake - self._sslobj.do_handshake() - ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 489, in send - resp = conn.urlopen( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen - retries = retries.increment( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\retry.py", line 592, in increment - raise MaxRetryError(_pool, url, error or ResponseError(cause)) - urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Max retries exceeded with url: /praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992)'))) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 223, in listing_pipeline_main - substring = scrape_listing_from_json(url) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 25, in scrape_listing_from_json - response = requests.get(url, timeout=timeout) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 73, in get - return request("get", url, params=params, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 59, in request - return session.request(method=method, url=url, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 587, in request - resp = self.send(prep, **send_kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 701, in send - r = adapter.send(request, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 563, in send - raise SSLError(e, request=request) - requests.exceptions.SSLError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Max retries exceeded with url: /praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992)')))
2023-04-24 03:31:01,302 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/client-implementation-engineer-warszawa-zajecza-15,oferta,1002513474 - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request - six.raise_from(e, None) - File "<string>", line 3, in raise_from - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request - httplib_response = conn.getresponse() -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1374, in getresponse - response.begin() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 318, in begin - version, status, reason = self._read_status() -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 279, in _read_status - line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1") -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto - return self._sock.recv_into(b) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1278, in recv_into - return self.read(nbytes, buffer) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1134, in read - return self._sslobj.read(len, buffer) -  - TimeoutError: The read operation timed out -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 489, in send - resp = conn.urlopen( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen - retries = retries.increment( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\retry.py", line 550, in increment - raise six.reraise(type(error), error, _stacktrace) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\packages\six.py", line 770, in reraise - raise value - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen - httplib_response = self._make_request( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 451, in _make_request - self._raise_timeout(err=e, url=url, timeout_value=read_timeout) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 340, in _raise_timeout - raise ReadTimeoutError( - urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Read timed out. (read timeout=5) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 223, in listing_pipeline_main - substring = scrape_listing_from_json(url) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 25, in scrape_listing_from_json - response = requests.get(url, timeout=timeout) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 73, in get - return request("get", url, params=params, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 59, in request - return session.request(method=method, url=url, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 587, in request - resp = self.send(prep, **send_kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 701, in send - r = adapter.send(request, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 578, in send - raise ReadTimeout(e, request=request) - requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Read timed out. (read timeout=5)
2023-04-24 03:33:17,250 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/starszy-specjalista-ds-rozwoju-narzedzi-oceny-ryzyka-kredytowego-warszawa,oferta,1002504274 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3005 (char 3004)
2023-04-24 03:35:09,555 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/rpa-developer-malopolskie,oferta,9884318 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3550 (char 3549)



2023-04-24 03:20:32,314 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen - httplib_response = self._make_request( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request - self._validate_conn(conn) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn - conn.connect() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connection.py", line 414, in connect - self.sock = ssl_wrap_socket( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket - ssl_sock = _ssl_wrap_socket_impl( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl - return ssl_context.wrap_socket(sock, server_hostname=server_hostname) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 517, in wrap_socket - return self.sslsocket_class._create( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1075, in _create - self.do_handshake() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1346, in do_handshake - self._sslobj.do_handshake() - ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 489, in send - resp = conn.urlopen( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen - retries = retries.increment( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\retry.py", line 592, in increment - raise MaxRetryError(_pool, url, error or ResponseError(cause)) - urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Max retries exceeded with url: /praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992)'))) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 223, in listing_pipeline_main - substring = scrape_listing_from_json(url) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 25, in scrape_listing_from_json - response = requests.get(url, timeout=timeout) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 73, in get - return request("get", url, params=params, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 59, in request - return session.request(method=method, url=url, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 587, in request - resp = self.send(prep, **send_kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 701, in send - r = adapter.send(request, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 563, in send - raise SSLError(e, request=request) - requests.exceptions.SSLError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Max retries exceeded with url: /praca/low-code-developer-poznan-aleje-solidarnosci-46,oferta,1002500897 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:992)')))

2023-04-24 03:31:01,302 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/client-implementation-engineer-warszawa-zajecza-15,oferta,1002513474 - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request - six.raise_from(e, None) - File "<string>", line 3, in raise_from - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request - httplib_response = conn.getresponse() -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1374, in getresponse - response.begin() - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 318, in begin - version, status, reason = self._read_status() -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 279, in _read_status - line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1") -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto - return self._sock.recv_into(b) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1278, in recv_into - return self.read(nbytes, buffer) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\ssl.py", line 1134, in read - return self._sslobj.read(len, buffer) -  - TimeoutError: The read operation timed out -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 489, in send - resp = conn.urlopen( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen - retries = retries.increment( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\retry.py", line 550, in increment - raise six.reraise(type(error), error, _stacktrace) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\packages\six.py", line 770, in reraise - raise value - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen - httplib_response = self._make_request( -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 451, in _make_request - self._raise_timeout(err=e, url=url, timeout_value=read_timeout) - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 340, in _raise_timeout - raise ReadTimeoutError( - urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Read timed out. (read timeout=5) -  - During handling of the above exception, another exception occurred: -  - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 223, in listing_pipeline_main - substring = scrape_listing_from_json(url) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 25, in scrape_listing_from_json - response = requests.get(url, timeout=timeout) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 73, in get - return request("get", url, params=params, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\api.py", line 59, in request - return session.request(method=method, url=url, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 587, in request - resp = self.send(prep, **send_kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\sessions.py", line 701, in send - r = adapter.send(request, **kwargs) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\site-packages\requests\adapters.py", line 578, in send - raise ReadTimeout(e, request=request) - requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.pracuj.pl', port=443): Read timed out. (read timeout=5)

2023-04-24 03:33:17,250 - main.scrape_listings - main - ERROR - log_exception - Scraping failed https://www.pracuj.pl/praca/starszy-specjalista-ds-rozwoju-narzedzi-oceny-ryzyka-kredytowego-warszawa,oferta,1002504274 - Traceback (most recent call last): - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 258, in main - listing_pipeline_main(url, _tech_set, succesfull) - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 226, in listing_pipeline_main - my_dict = change_str_to_dict(substring) -  - File "c:\Users\Artur\Documents\GitHub\Web-Scraping_Job_Site\scrape_listings.py", line 72, in change_str_to_dict - my_dict = json.loads(substring) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\__init__.py", line 346, in loads - return _default_decoder.decode(s) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode - obj, end = self.raw_decode(s, idx=_w(s, 0).end()) -  - File "C:\Users\Artur\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 353, in raw_decode - obj, end = self.scan_once(s, idx) -  - json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 3005 (char 3004)
